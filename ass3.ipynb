{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0a0+6ddf5cf85e.nv24.04'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination in one class (NO REDUNDANT CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Recommender, self).__init__()\n",
    "        \n",
    "        self.embedding_user = torch.nn.Embedding(num_embeddings=config['num_users'], embedding_dim=config['latent_dim'])\n",
    "        self.embedding_item = torch.nn.Embedding(num_embeddings=config['num_items'], embedding_dim=config['latent_dim'])\n",
    "        \n",
    "        ## MLP part\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        \n",
    "        self.logits = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim'], out_features=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.model_type = config['model_type']\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        \n",
    "        if self.model_type == 'GMF':\n",
    "            vector = torch.mul(user_embedding, item_embedding)\n",
    "        elif self.model_type == 'MLP':\n",
    "            vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "            for fc_layer in self.fc_layers:\n",
    "                vector = fc_layer(vector)\n",
    "                vector = torch.nn.ReLU()(vector)\n",
    "        elif self.model_type == 'NeuMF':\n",
    "            gmf_vector = torch.mul(user_embedding, item_embedding)\n",
    "            mlp_vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "            for fc_layer in self.fc_layers:\n",
    "                mlp_vector = fc_layer(mlp_vector)\n",
    "                mlp_vector = torch.nn.ReLU()(mlp_vector)\n",
    "            vector = torch.cat([gmf_vector, mlp_vector], dim=-1)\n",
    "        \n",
    "        # logits = self.logits(vector)\n",
    "        # output = self.sigmoid(logits)\n",
    "        output = self.sigmoid(vector)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.sparse as sp\n",
    "\n",
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = self.load_rating_file_as_tensor(filename)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def load_rating_file_as_tensor(self, filename):\n",
    "        ratingList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                ratingList.append([user, item, rating])\n",
    "        return torch.tensor(ratingList, dtype=torch.float32)\n",
    "\n",
    "class NegativeDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.data = self.load_negative_file_as_tensor(filename)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def load_negative_file_as_tensor(self, filename):\n",
    "        negativeList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                arr = line.split(\"\\t\")\n",
    "                negatives = [int(x) for x in arr[1:]]\n",
    "                negativeList.append(negatives)\n",
    "        return torch.tensor(negativeList, dtype=torch.int32)\n",
    "\n",
    "def load_rating_file_as_sparse(filename):\n",
    "    num_users, num_items = 0, 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            arr = line.split(\"\\t\")\n",
    "            user, item = int(arr[0]), int(arr[1])\n",
    "            num_users = max(num_users, user)\n",
    "            num_items = max(num_items, item)\n",
    "\n",
    "    mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            arr = line.split(\"\\t\")\n",
    "            user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "            if rating > 0:\n",
    "                mat[user, item] = rating\n",
    "    return mat.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994164</th>\n",
       "      <td>6039</td>\n",
       "      <td>1092</td>\n",
       "      <td>5</td>\n",
       "      <td>956703977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994165</th>\n",
       "      <td>6039</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>956703977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994166</th>\n",
       "      <td>6039</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>956703954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994167</th>\n",
       "      <td>6039</td>\n",
       "      <td>323</td>\n",
       "      <td>4</td>\n",
       "      <td>956703954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994168</th>\n",
       "      <td>6039</td>\n",
       "      <td>669</td>\n",
       "      <td>4</td>\n",
       "      <td>956703932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid   mid  rating  timestamp\n",
       "0          0    32       4  978824330\n",
       "1          0    34       4  978824330\n",
       "2          0     4       5  978824291\n",
       "3          0    35       4  978824291\n",
       "4          0    30       4  978824291\n",
       "...      ...   ...     ...        ...\n",
       "994164  6039  1092       5  956703977\n",
       "994165  6039    41       4  956703977\n",
       "994166  6039   128       5  956703954\n",
       "994167  6039   323       4  956703954\n",
       "994168  6039   669       4  956703932\n",
       "\n",
       "[994169 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Data/ml-1m.train.rating\",sep='\\t', header=None, names=['uid', 'mid', 'rating', 'timestamp'], engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0,25)</td>\n",
       "      <td>1064</td>\n",
       "      <td>174</td>\n",
       "      <td>2791</td>\n",
       "      <td>3373</td>\n",
       "      <td>269</td>\n",
       "      <td>2678</td>\n",
       "      <td>1902</td>\n",
       "      <td>3641</td>\n",
       "      <td>1216</td>\n",
       "      <td>...</td>\n",
       "      <td>2854</td>\n",
       "      <td>3067</td>\n",
       "      <td>58</td>\n",
       "      <td>2551</td>\n",
       "      <td>2333</td>\n",
       "      <td>2688</td>\n",
       "      <td>3703</td>\n",
       "      <td>1300</td>\n",
       "      <td>1924</td>\n",
       "      <td>3118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1,133)</td>\n",
       "      <td>1072</td>\n",
       "      <td>3154</td>\n",
       "      <td>3368</td>\n",
       "      <td>3644</td>\n",
       "      <td>549</td>\n",
       "      <td>1810</td>\n",
       "      <td>937</td>\n",
       "      <td>1514</td>\n",
       "      <td>1713</td>\n",
       "      <td>...</td>\n",
       "      <td>1535</td>\n",
       "      <td>341</td>\n",
       "      <td>3525</td>\n",
       "      <td>1429</td>\n",
       "      <td>2225</td>\n",
       "      <td>1628</td>\n",
       "      <td>2061</td>\n",
       "      <td>469</td>\n",
       "      <td>3056</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2,207)</td>\n",
       "      <td>2216</td>\n",
       "      <td>209</td>\n",
       "      <td>2347</td>\n",
       "      <td>3</td>\n",
       "      <td>1652</td>\n",
       "      <td>3397</td>\n",
       "      <td>383</td>\n",
       "      <td>2905</td>\n",
       "      <td>2284</td>\n",
       "      <td>...</td>\n",
       "      <td>953</td>\n",
       "      <td>865</td>\n",
       "      <td>813</td>\n",
       "      <td>1353</td>\n",
       "      <td>2945</td>\n",
       "      <td>2580</td>\n",
       "      <td>2989</td>\n",
       "      <td>2790</td>\n",
       "      <td>2879</td>\n",
       "      <td>2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(3,208)</td>\n",
       "      <td>3023</td>\n",
       "      <td>1489</td>\n",
       "      <td>1916</td>\n",
       "      <td>1706</td>\n",
       "      <td>1221</td>\n",
       "      <td>1191</td>\n",
       "      <td>2671</td>\n",
       "      <td>81</td>\n",
       "      <td>2483</td>\n",
       "      <td>...</td>\n",
       "      <td>3347</td>\n",
       "      <td>1707</td>\n",
       "      <td>2901</td>\n",
       "      <td>2767</td>\n",
       "      <td>2167</td>\n",
       "      <td>1921</td>\n",
       "      <td>247</td>\n",
       "      <td>1618</td>\n",
       "      <td>2016</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4,222)</td>\n",
       "      <td>1794</td>\n",
       "      <td>3535</td>\n",
       "      <td>108</td>\n",
       "      <td>593</td>\n",
       "      <td>466</td>\n",
       "      <td>2048</td>\n",
       "      <td>854</td>\n",
       "      <td>1378</td>\n",
       "      <td>1301</td>\n",
       "      <td>...</td>\n",
       "      <td>2490</td>\n",
       "      <td>1332</td>\n",
       "      <td>2526</td>\n",
       "      <td>2804</td>\n",
       "      <td>2027</td>\n",
       "      <td>833</td>\n",
       "      <td>176</td>\n",
       "      <td>463</td>\n",
       "      <td>2851</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>(6035,1048)</td>\n",
       "      <td>2495</td>\n",
       "      <td>3406</td>\n",
       "      <td>819</td>\n",
       "      <td>729</td>\n",
       "      <td>1920</td>\n",
       "      <td>2003</td>\n",
       "      <td>3329</td>\n",
       "      <td>2351</td>\n",
       "      <td>549</td>\n",
       "      <td>...</td>\n",
       "      <td>2583</td>\n",
       "      <td>2905</td>\n",
       "      <td>2713</td>\n",
       "      <td>2361</td>\n",
       "      <td>2542</td>\n",
       "      <td>2598</td>\n",
       "      <td>2030</td>\n",
       "      <td>2984</td>\n",
       "      <td>3382</td>\n",
       "      <td>2771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>(6036,294)</td>\n",
       "      <td>2248</td>\n",
       "      <td>1318</td>\n",
       "      <td>3661</td>\n",
       "      <td>72</td>\n",
       "      <td>351</td>\n",
       "      <td>2131</td>\n",
       "      <td>3281</td>\n",
       "      <td>2482</td>\n",
       "      <td>639</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>508</td>\n",
       "      <td>2168</td>\n",
       "      <td>354</td>\n",
       "      <td>1156</td>\n",
       "      <td>1646</td>\n",
       "      <td>3238</td>\n",
       "      <td>2091</td>\n",
       "      <td>1494</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>(6037,1528)</td>\n",
       "      <td>2194</td>\n",
       "      <td>867</td>\n",
       "      <td>1424</td>\n",
       "      <td>2517</td>\n",
       "      <td>3080</td>\n",
       "      <td>2789</td>\n",
       "      <td>1210</td>\n",
       "      <td>3150</td>\n",
       "      <td>466</td>\n",
       "      <td>...</td>\n",
       "      <td>1428</td>\n",
       "      <td>433</td>\n",
       "      <td>74</td>\n",
       "      <td>3457</td>\n",
       "      <td>833</td>\n",
       "      <td>2823</td>\n",
       "      <td>2425</td>\n",
       "      <td>3434</td>\n",
       "      <td>2331</td>\n",
       "      <td>2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>(6038,1449)</td>\n",
       "      <td>2606</td>\n",
       "      <td>2054</td>\n",
       "      <td>2754</td>\n",
       "      <td>1299</td>\n",
       "      <td>2854</td>\n",
       "      <td>2413</td>\n",
       "      <td>1055</td>\n",
       "      <td>742</td>\n",
       "      <td>2876</td>\n",
       "      <td>...</td>\n",
       "      <td>2140</td>\n",
       "      <td>3401</td>\n",
       "      <td>813</td>\n",
       "      <td>1374</td>\n",
       "      <td>307</td>\n",
       "      <td>1477</td>\n",
       "      <td>2327</td>\n",
       "      <td>114</td>\n",
       "      <td>98</td>\n",
       "      <td>3021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>(6039,434)</td>\n",
       "      <td>3289</td>\n",
       "      <td>3432</td>\n",
       "      <td>2599</td>\n",
       "      <td>2162</td>\n",
       "      <td>1653</td>\n",
       "      <td>2363</td>\n",
       "      <td>2576</td>\n",
       "      <td>1315</td>\n",
       "      <td>3255</td>\n",
       "      <td>...</td>\n",
       "      <td>394</td>\n",
       "      <td>195</td>\n",
       "      <td>1698</td>\n",
       "      <td>110</td>\n",
       "      <td>1985</td>\n",
       "      <td>873</td>\n",
       "      <td>674</td>\n",
       "      <td>555</td>\n",
       "      <td>746</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1     2     3     4     5     6     7     8     9   ...  \\\n",
       "0          (0,25)  1064   174  2791  3373   269  2678  1902  3641  1216  ...   \n",
       "1         (1,133)  1072  3154  3368  3644   549  1810   937  1514  1713  ...   \n",
       "2         (2,207)  2216   209  2347     3  1652  3397   383  2905  2284  ...   \n",
       "3         (3,208)  3023  1489  1916  1706  1221  1191  2671    81  2483  ...   \n",
       "4         (4,222)  1794  3535   108   593   466  2048   854  1378  1301  ...   \n",
       "...           ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "6035  (6035,1048)  2495  3406   819   729  1920  2003  3329  2351   549  ...   \n",
       "6036   (6036,294)  2248  1318  3661    72   351  2131  3281  2482   639  ...   \n",
       "6037  (6037,1528)  2194   867  1424  2517  3080  2789  1210  3150   466  ...   \n",
       "6038  (6038,1449)  2606  2054  2754  1299  2854  2413  1055   742  2876  ...   \n",
       "6039   (6039,434)  3289  3432  2599  2162  1653  2363  2576  1315  3255  ...   \n",
       "\n",
       "        90    91    92    93    94    95    96    97    98    99  \n",
       "0     2854  3067    58  2551  2333  2688  3703  1300  1924  3118  \n",
       "1     1535   341  3525  1429  2225  1628  2061   469  3056  2553  \n",
       "2      953   865   813  1353  2945  2580  2989  2790  2879  2481  \n",
       "3     3347  1707  2901  2767  2167  1921   247  1618  2016  2323  \n",
       "4     2490  1332  2526  2804  2027   833   176   463  2851  2453  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "6035  2583  2905  2713  2361  2542  2598  2030  2984  3382  2771  \n",
       "6036   110   508  2168   354  1156  1646  3238  2091  1494  2489  \n",
       "6037  1428   433    74  3457   833  2823  2425  3434  2331  2530  \n",
       "6038  2140  3401   813  1374   307  1477  2327   114    98  3021  \n",
       "6039   394   195  1698   110  1985   873   674   555   746  1526  \n",
       "\n",
       "[6040 rows x 100 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"Data/ml-1m.test.negative\",sep = \"\\t\",header=None)\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RatingDataset(\"Data/ml-1m.train.rating\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "test_ratings = RatingDataset(\"Data/ml-1m.test.rating\")\n",
    "test_negatives = NegativeDataset(\"Data/ml-1m.test.negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 加载评分数据为稀疏矩阵\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mload_rating_file_as_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain.rating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 44\u001b[0m, in \u001b[0;36mload_rating_file_as_sparse\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_rating_file_as_sparse\u001b[39m(filename):\n\u001b[1;32m     43\u001b[0m     num_users, num_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[1;32m     46\u001b[0m             arr \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.rating'"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch in train_dataloader:\n",
    "    # 进行模型训练\n",
    "    pass\n",
    "\n",
    "# 加载评分数据为稀疏矩阵\n",
    "# train_matrix = load_rating_file_as_sparse(\"train.rating\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trian and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     'num_users': 1000,\n",
    "#     'num_items': 2000,\n",
    "#     'latent_dim': 8,\n",
    "#     'layers': [64, 32, 16],\n",
    "#     'model_type': 'GMF'     #　MLP, NeuMF\n",
    "# }\n",
    "\n",
    "# user_indices = \n",
    "# item_indices = \n",
    "# recommender = Recommender(config)\n",
    "# output = recommender(user_indices, item_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Recommender().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "output = model(input)  # 模型的输出，是一个概率值\n",
    "loss = criterion(output, target)  # 计算逻辑回归损失\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
