{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from tqdm import  tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.backends.cudnn.enabled = True\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Pytorch's version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0a0+6ddf5cf85e.nv24.04\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a quick look of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1  2          3\n",
       "0  0  32  4  978824330\n",
       "1  0  34  4  978824330\n",
       "2  0   4  5  978824291\n",
       "3  0  35  4  978824291\n",
       "4  0  30  4  978824291"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(\"Data/ml-1m.train.rating\",sep=\"\\t\",header=None)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self._num_users = config['num_users']\n",
    "        self._num_items = config['num_items']\n",
    "        self._X = config['layer_X']\n",
    "        self._factor = config['factor']\n",
    "        self._embedding_size_gmf = self._factor\n",
    "        self._embedding_size_mlp = self._factor*(2**(self._X-1))\n",
    "\n",
    "        self._embedding__user_gmf = nn.Embedding(self._num_users, self._embedding_size_gmf)\n",
    "        self._embedding__item_gmf = nn.Embedding(self._num_items, self._embedding_size_gmf)\n",
    "\n",
    "        if self._X > 0:\n",
    "            self._embedding__user_mlp = nn.Embedding(self._num_users, self._embedding_size_mlp)\n",
    "            self._embedding__item_mlp = nn.Embedding(self._num_items, self._embedding_size_mlp)\n",
    "\n",
    "            self._fc_layers = nn.ModuleList()\n",
    "            for idx in range(self._X-1, -1, -1):\n",
    "                in_size = self._factor*(2**(idx+1))\n",
    "                out_size = self._factor*(2**idx)\n",
    "                self._fc_layers.append(nn.Linear(in_size, out_size))\n",
    "        self._out_fc = nn.Linear(self._factor, 1, bias=False)\n",
    "        \n",
    "        self._activate1 = nn.Sigmoid()\n",
    "        self._activate2 = nn.ReLU()\n",
    "    def __repr__(self):\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GMF(NCF,nn.Module):\n",
    "#     def __init__(self, config):\n",
    "#         nn.Module.__init__(self)\n",
    "#         NCF.__init__(self, config)\n",
    "\n",
    "#     def forward(self, user_idx, item_idx):\n",
    "#         user_embedding = self._embedding__user_gmf(user_idx)\n",
    "#         item_embedding = self._embedding__item_gmf(item_idx)\n",
    "#         pointwise_vector = torch.mul(user_embedding, item_embedding)\n",
    "#         logit = self._out_fc(pointwise_vector)\n",
    "#         prob = self._activate1(logit)\n",
    "#         return prob.squeeze(1)\n",
    "\n",
    "class GMF(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(GMF,self).__init__()\n",
    "        self.config = config\n",
    "        self._num_users = config['num_users']\n",
    "        self._num_items = config['num_items']\n",
    "        self._factor = config['factor']\n",
    "        self._embedding_size_gmf = self._factor\n",
    "        self._embedding__user_gmf = nn.Embedding(self._num_users, self._embedding_size_gmf)\n",
    "        self._embedding__item_gmf = nn.Embedding(self._num_items, self._embedding_size_gmf)\n",
    "        self._out_fc = nn.Linear(self._factor, 1, bias=False)\n",
    "        self._activate1 = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        user_embedding = self._embedding__user_gmf(user_idx)\n",
    "        item_embedding = self._embedding__item_gmf(item_idx)\n",
    "        pointwise_vector = torch.mul(user_embedding, item_embedding)\n",
    "        logit = self._out_fc(pointwise_vector)\n",
    "        prob = self._activate1(logit)\n",
    "        return prob.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(NCF,nn.Module):\n",
    "    def __init__(self, config):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        user_embedding = self._embedding__user_mlp(user_idx)\n",
    "        item_embedding = self._embedding__item_mlp(item_idx)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for _, layer in enumerate(self._fc_layers):\n",
    "            vector = layer(vector)\n",
    "            vector = self._activate2(vector)\n",
    "        logit = self._out_fc(vector)\n",
    "        prob = self._activate1(logit)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(NCF,nn.Module):\n",
    "    def __init__(self, config):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config)\n",
    "        self._neumf_fc = nn.Linear(self._factor*2, 1, bias=False)\n",
    "    \n",
    "    def forward(self, user_idx, item_idx):\n",
    "        user_embedding_gmf = self._embedding__user_gmf(user_idx)\n",
    "        item_embedding_gmf = self._embedding__item_gmf(item_idx)\n",
    "        pointwise_vector_gmf = torch.mul(user_embedding_gmf, item_embedding_gmf)\n",
    "\n",
    "        user_embedding_mlp = self._embedding__user_mlp(user_idx)\n",
    "        item_embedding_mlp = self._embedding__item_mlp(item_idx)\n",
    "        vector_mlp = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "        for _, layer in enumerate(self._fc_layers):\n",
    "            vector_mlp = layer(vector_mlp)\n",
    "            vector_mlp = self._activate2(vector_mlp)\n",
    "\n",
    "        vector_neumf = torch.cat([pointwise_vector_gmf, vector_mlp], dim=-1)\n",
    "        logit = self._neumf_fc(vector_neumf)\n",
    "        prob = self._activate1(logit)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMF_config = {'num_users': 6040, 'num_items': 3706, 'factor': 8, 'layer_X': 0}\n",
    "MLP_config = {'num_users': 6040, 'num_items': 3706, 'factor': 8, 'layer_X': 3}\n",
    "NeuMF_config = {'num_users': 6040, 'num_items': 3706, 'factor': 8, 'layer_X': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMF(\n",
       "  (_embedding__user_gmf): Embedding(6040, 8)\n",
       "  (_embedding__item_gmf): Embedding(3706, 8)\n",
       "  (_out_fc): Linear(in_features=8, out_features=1, bias=False)\n",
       "  (_activate1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GMF_model = GMF(GMF_config)\n",
    "GMF_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self.1 : __torch__.GMF,\n",
      "      %user_idx : Long(1, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %item_idx : Long(1, strides=[1], requires_grad=0, device=cuda:0)):\n",
      "  %_activate1 : __torch__.torch.nn.modules.activation.Sigmoid = prim::GetAttr[name=\"_activate1\"](%self.1)\n",
      "  %_out_fc : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=\"_out_fc\"](%self.1)\n",
      "  %_embedding__item_gmf : __torch__.torch.nn.modules.sparse.___torch_mangle_0.Embedding = prim::GetAttr[name=\"_embedding__item_gmf\"](%self.1)\n",
      "  %_embedding__user_gmf : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name=\"_embedding__user_gmf\"](%self.1)\n",
      "  %50 : Tensor = prim::CallMethod[name=\"forward\"](%_embedding__user_gmf, %user_idx)\n",
      "  %51 : Tensor = prim::CallMethod[name=\"forward\"](%_embedding__item_gmf, %item_idx)\n",
      "  %input.1 : Float(1, 8, strides=[8, 1], requires_grad=1, device=cuda:0) = aten::mul(%50, %51) # /tmp/ipykernel_20891/167587794.py:9:0\n",
      "  %52 : Tensor = prim::CallMethod[name=\"forward\"](%_out_fc, %input.1)\n",
      "  %53 : Tensor = prim::CallMethod[name=\"forward\"](%_activate1, %52)\n",
      "  return (%53)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate random user_idx and item_idx\n",
    "user_idx = torch.randint(0, GMF_config['num_users'], (1,)).to(device)\n",
    "item_idx = torch.randint(0, GMF_config['num_items'], (1,)).to(device)\n",
    "\n",
    "# using torch.jit.trace to trace model\n",
    "traced_model = torch.jit.trace(GMF_model, (user_idx, item_idx))\n",
    "\n",
    "print(traced_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_model = MLP(MLP_config)\n",
    "MLP_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuMF_model = NeuMF(NeuMF_config)\n",
    "NeuMF_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, path):\n",
    "        self.trainMatrix = self.load_rating_file_as_matrix(path + \".train.rating\")\n",
    "        self.testRatings = self.load_rating_file_as_list(path + \".test.rating\")\n",
    "        self.testNegatives = self.load_negative_file(path + \".test.negative\")\n",
    "        assert len(self.testRatings) == len(self.testNegatives)\n",
    "        self.num_users, self.num_items = self.trainMatrix.shape\n",
    "        \n",
    "    def load_rating_file_as_list(self, filename):\n",
    "        ratingList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item = int(arr[0]), int(arr[1])\n",
    "                ratingList.append([user, item])\n",
    "                line = f.readline()\n",
    "        return ratingList\n",
    "    \n",
    "    def load_negative_file(self, filename):\n",
    "        negativeList = []\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                negatives = []\n",
    "                for x in arr[1: ]:\n",
    "                    negatives.append(int(x))\n",
    "                negativeList.append(negatives)\n",
    "                line = f.readline()\n",
    "        return negativeList\n",
    "    \n",
    "    def load_rating_file_as_matrix(self, filename):\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                u, i = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, u)\n",
    "                num_items = max(num_items, i)\n",
    "                line = f.readline()\n",
    "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                if (rating > 0):\n",
    "                    mat[user, item] = 1.0\n",
    "                line = f.readline()    \n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\"./Data/\"+\"ml-1m\")\n",
    "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
    "num_users, num_items = train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding negative samples to trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u, j) in train:\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create traindataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class mlDataset(Dataset):\n",
    "    def __init__(self, user_input, item_input, labels):\n",
    "        self.user_input = user_input\n",
    "        self.item_input = item_input\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, index):\n",
    "        return self.user_input[index], self.item_input[index], self.labels[index]\n",
    "user_input, item_input, labels = get_train_instances(train, num_negatives=4)\n",
    "train_dataset = mlDataset(user_input, item_input, labels)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=256, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,topk):\n",
    "    class testDataset(Dataset):\n",
    "        def __init__(self, rating, negative_lists):\n",
    "            self.rating = rating\n",
    "            self.negative_lists = negative_lists\n",
    "        def __len__(self):\n",
    "            return len(self.rating)\n",
    "        def __getitem__(self, index):\n",
    "            return self.rating[index], self.negative_lists[index]\n",
    "\n",
    "    def HR_NDCG(testloader):\n",
    "        model.eval()\n",
    "        ht = 0; ndcg = 0\n",
    "        with torch.no_grad():\n",
    "            for rating, negatives in testloader:\n",
    "                user_idxs = rating[0].clone().detach().to(device)\n",
    "                pos_item_idxs = rating[1].clone().detach().to(device)\n",
    "                neg_item_idxs = torch.stack(negatives).to(device) # 99*256\n",
    "\n",
    "                pos_scores = model(user_idxs, pos_item_idxs).unsqueeze(1) # (batch_size, 1)\n",
    "                neg_scores = model(user_idxs.unsqueeze(0).repeat(neg_item_idxs.size(0), 1), neg_item_idxs).squeeze(2).t()  # (batch_size, num_negatives)\n",
    "                all_scores = torch.cat((pos_scores, neg_scores), dim=1)  # (batch_size, num_negatives+1)\n",
    "\n",
    "                # calculate HR\n",
    "                _, topk_indices = torch.topk(all_scores, topk, dim=1, largest=True, sorted=True)\n",
    "                ht += torch.sum((topk_indices == 0).int()).item()  # 0 is the index of positive example in concatenated scores\n",
    "\n",
    "                # calculate NDCG\n",
    "                sorted_scores, _ = torch.sort(all_scores, dim=1, descending=True)\n",
    "                _, rankings = torch.where(pos_scores == sorted_scores)\n",
    "                ndcg += torch.sum(1 / torch.log2(rankings + 2)).item()\n",
    "                print(\"-----------------------------------\")\n",
    "\n",
    "        return ht / len(testloader.dataset), ndcg / len(testloader.dataset)\n",
    "\n",
    "    test_dataset = testDataset(testRatings, testNegatives)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    hr, ndcg = HR_NDCG(test_loader)\n",
    "    return hr, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(GMF_model,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(GMF_model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(GMF_model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss() #期望的输入是经过sigmoid函数处理的，此处应该选用BCELoss而不是BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    GMF_model.train()\n",
    "    running_loss = 0\n",
    "    for user_idxs, item_idxs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user_idxs = user_idxs.to(device)\n",
    "        item_idxs = item_idxs.to(device)\n",
    "        labels = labels.float().to(device)\n",
    "\n",
    "        outputs = GMF_model(user_idxs, item_idxs)\n",
    "        # loss = criterion(outputs, labels.unsqueeze(1))\n",
    "        # print(outputs)\n",
    "        # print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataset):.4f}')\n",
    "    HR, NDCG = evaluate(GMF_model, topk)\n",
    "    print(f'HR@{topk}: {HR:.4f}, NDCG@{topk}: {NDCG:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
